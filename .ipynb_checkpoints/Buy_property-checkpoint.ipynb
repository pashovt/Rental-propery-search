{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b859414",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rightmove-webscraper"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -yrsistent (c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading rightmove_webscraper-1.1.2-py3-none-any.whl (7.6 kB)\n",
      "Collecting requests>=2.27.1\n",
      "  Downloading requests-2.28.0-py3-none-any.whl (62 kB)\n",
      "Collecting numpy>=1.22.3\n",
      "  Downloading numpy-1.22.4-cp38-cp38-win32.whl (12.3 MB)\n",
      "Collecting lxml>=4.8.0\n",
      "  Downloading lxml-4.9.0-cp38-cp38-win32.whl (3.3 MB)\n",
      "Collecting pandas>=1.4.1\n",
      "  Downloading pandas-1.4.2-cp38-cp38-win32.whl (9.4 MB)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas>=1.4.1->rightmove-webscraper) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from pandas>=1.4.1->rightmove-webscraper) (2.8.1)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests>=2.27.1->rightmove-webscraper) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests>=2.27.1->rightmove-webscraper) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from requests>=2.27.1->rightmove-webscraper) (2021.5.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pasho\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.4.1->rightmove-webscraper) (1.16.0)\n",
      "Installing collected packages: numpy, charset-normalizer, requests, pandas, lxml, rightmove-webscraper\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.2.4\n",
      "    Uninstalling pandas-1.2.4:\n",
      "      Successfully uninstalled pandas-1.2.4\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.6.3\n",
      "    Uninstalling lxml-4.6.3:\n",
      "      Successfully uninstalled lxml-4.6.3\n",
      "Successfully installed charset-normalizer-2.0.12 lxml-4.9.0 numpy-1.22.4 pandas-1.4.2 requests-2.28.0 rightmove-webscraper-1.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -U rightmove-webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72db6af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib.request\n",
    "import csv\n",
    "import requests\n",
    "# import folium\n",
    "# from folium.plugins import MarkerCluster\n",
    "# from geopy.geocoders import Nominatim\n",
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rightmove_webscraper import RightmoveData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c460183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# House data\n",
    "    # Get data from websites\n",
    "    # check if property value correct or overpriced based on previously sold houses in the 3 adjecent streets in the last 6 months to 2 years\n",
    "# Mortgage\n",
    "    # Calculate maximum years of mortgage\n",
    "    # Calculate the amount of loan that will be able to be taken and monthly repaiment/interest rate\n",
    "    # Calculate maximum property value/property affordability based on mortgage and deposit\n",
    "\n",
    "# https://github.com/toby-p/rightmove_webscraper.py\n",
    "# https://blog.apify.com/is-web-scraping-legal/#terms-of-use-and-scraping\n",
    "# http://rightmove.co.uk/robots.txt\n",
    "# http://www.rightmove.co.uk/sitemap.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4157cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_builder(identifier='REGION'):\n",
    "    _locations = locations[identifier]\n",
    "    for loc in _locations:\n",
    "        url = f'https://www.rightmove.co.uk/property-for-sale/find.html?searchType={sale_or_rent}&locationIdentifier={identifier}%{loc}&insId=1&radius={radius}&minPrice={min_price}&maxPrice={max_price}&minBedrooms={min_bed}&maxBedrooms={max_bed}&displayPropertyType=&maxDaysSinceAdded=14&_includeSSTC=on&sortByPriceDescending=&primaryDisplayPropertyType=&secondaryDisplayPropertyType=&oldDisplayPropertyType=&oldPrimaryDisplayPropertyType=&newHome=&auction=false'\n",
    "        yield url\n",
    "\n",
    "def dataset_builder():\n",
    "    outputset = pd.DataFrame()\n",
    "    url = url_builder()\n",
    "    data = RightmoveData(url)._get_results()\n",
    "    outputset = pd.concat([outputset, data])\n",
    "    \n",
    "def ifisdigit(feature):\n",
    "    s_list = [int(s) for s in feature.split() if s.isdigit()]\n",
    "    if s_list:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8bfbe593",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_data = pd.DataFrame(columns=['property link', 'property address', 'property value',\n",
    "    'offer type', 'property type', 'bedrooms', 'bathrooms', 'blueprint link', 'agency name', \n",
    "    'agency address', 'agency link', 'agency telephone', 'contact form', 'features', \n",
    "    'property description', 'cash', 'shared', 'share value', 'auction', 'ECP link'])\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "sale_or_rent = 'SALE' # 'RENT'\n",
    "location = '5E2205'\n",
    "\n",
    "# https://www.reddit.com/r/nottingham/comments/9mo4ou/nice_areas_to_live_around_nottingham/\n",
    "# OUTCODE\n",
    "NG1 = '5E1752' # NG1 - Centre \n",
    "NG2 = '5E1763' # NG2 - West bridgeford\n",
    "NG3 = '5E1770' # NG3 - Saint ann, sneigton\n",
    "NG4 = '5E1775' # NG4 - Netherfield\n",
    "NG5 = '5E1776' # NG5 - Arnold\n",
    "NG6 = '5E1777' # NG6 - Bulwell\n",
    "NG7 = '5E1778' # NG7 - The park\n",
    "NG8 = '5E1780' # NG8 - Hyson Green\n",
    "NG9 = '5E1781' # NG9 - Beston\n",
    "# REGION\n",
    "Arnold = '5E2205'\n",
    "Beeston = '5E3205'\n",
    "Mapperley = '5E93530'\n",
    "ThePark = '5E24206'\n",
    "# Ruddington = '5E21243'\n",
    "WestBridgford = '5E26169'\n",
    "# Woodborough = '5E27299'\n",
    "Carlton = '5E5612'\n",
    "Wollaton = '5E27250'\n",
    "\n",
    "locations = {'OUTCODE': [NG1, NG2, NG3,\n",
    "                        NG4, NG5, NG6,\n",
    "                        NG7, NG8, NG9],\n",
    "             'REGION': [Arnold, Beeston, Mapperley,\n",
    "                       ThePark, WestBridgford, Carlton,\n",
    "                       Wollaton]}\n",
    "\n",
    "# search properties\n",
    "min_bed = 2 # bedrooms\n",
    "max_bed = 4 # bedrooms\n",
    "min_price = 0 # pounds\n",
    "max_price = 200000 # pounds\n",
    "radius = 1 # mile\n",
    "# property_type = 'house'\n",
    "# distance_list = [0.25, 0.5, 1, 3, 5, 10, 15, 30, 40, 50, 75, 100]\n",
    "\n",
    "urls = url_builder()\n",
    "for url in urls:\n",
    "    temporary_data = RightmoveData(url)._get_results()\n",
    "    data = pd.concat([data, temporary_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c72eddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['url'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80afeabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for link in data['url']:\n",
    "\n",
    "    property_base_url = link[:link.find('#')]\n",
    "    agencies_base_url = 'http://www.rightmove.co.uk/'\n",
    "\n",
    "    r = requests.get(property_base_url)\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "\n",
    "    property_address = soup.find(class_=\"_2uQQ3SV0eMHL1P6t5ZDo2q\").text if soup.find(class_=\"_2uQQ3SV0eMHL1P6t5ZDo2q\").text else None # address\n",
    "    property_value = soup.find(class_=\"_1gfnqJ3Vtd1z40MlC0MzXu\").text if soup.find(class_=\"_1gfnqJ3Vtd1z40MlC0MzXu\") else None\n",
    "    offer_type = soup.find(class_=\"_16Ww3GEBGqbC4V9u-pm3MT\").text if soup.find(class_=\"_16Ww3GEBGqbC4V9u-pm3MT\") else None # price class\n",
    "    property_type = soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")[0].text if len(soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")) > 0 else None # property type\n",
    "    property_bedrooms = soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")[1].text[1:] if len(soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")) > 1 else None # bedrooms\n",
    "    property_bathrooms = soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")[2].text[1:] if len(soup.find_all(class_=\"_1hV1kqpVceE9m-QrX_hWDN\")) > 2 else None # bathrooms\n",
    "    blueprint_url = property_base_url + soup.find(class_='_1EKvilxkEc0XS32Gwbn-iU').get('href') if soup.find(class_='_1EKvilxkEc0XS32Gwbn-iU') else None # blueprint link\n",
    "\n",
    "\n",
    "    # agency details\n",
    "    agency_name = soup.find(class_=\"_3PpywCmRYxC0B-ShNWxstv\").text if soup.find(class_=\"_3PpywCmRYxC0B-ShNWxstv\") else None # agency name\n",
    "    agency_address = soup.find(class_=\"_1zJF3rohTQLpqNFDBD59qt\").text if soup.find(class_=\"_1zJF3rohTQLpqNFDBD59qt\") else None # agency address\n",
    "    agency_link = agencies_base_url+soup.find(class_=\"YrIZhB0KLTi_J-sEv5dJa\").get('href') if soup.find(class_=\"YrIZhB0KLTi_J-sEv5dJa\") else None # agency link\n",
    "    agency_telephone = soup.find(class_=\"_3fRacUNSjSxx6ntRK-jShL\").get('href') if soup.find(class_=\"_3fRacUNSjSxx6ntRK-jShL\") else None # telephone\n",
    "    agency_contact_form = agencies_base_url + soup.find(class_=\"_3RZrxRVj_9Dn-Ot3w1ZjcX _1bauMPjK37TtcFKTHFxjlF\").get('href') if soup.find(class_=\"_3RZrxRVj_9Dn-Ot3w1ZjcX _1bauMPjK37TtcFKTHFxjlF\") else None # contact form\n",
    "\n",
    "    key_features = [li.text for li in soup.find(class_='_1uI3IvdF5sIuBtRIvKrreQ').children] if soup.find(class_='_1uI3IvdF5sIuBtRIvKrreQ') else None #key features\n",
    "    property_description = soup.find(class_='STw8udCxUaBUMfOOZu0iL').text if soup.find(class_='STw8udCxUaBUMfOOZu0iL') else None # text\n",
    "\n",
    "\n",
    "\n",
    "    # cash buyers\n",
    "    cash = None\n",
    "    if key_features:\n",
    "        possible_cash = [feature for feature in key_features if all(x in feature for x in ['cash', 'only'])]\n",
    "        if possible_cash:\n",
    "            cash = possible_cash\n",
    "    else:\n",
    "        if all(x in property_description for x in ['cash', 'only']):\n",
    "            cash = True\n",
    "\n",
    "    # shared ownership, percent, total property value\n",
    "    share_value = None\n",
    "    shared = True if 'shared ownership' in property_description.lower() else None # or 'shared ownership' in \n",
    "    if shared:\n",
    "        value_index = property_description.lower().find('market value') if property_description.lower().find('market value') else ''\n",
    "        s = property_description[value_index:value_index+50]\n",
    "        s = s.replace(',', '').replace('£', '')\n",
    "        property_value = [int(s) for s in s.split() if s.isdigit()][0] if [int(s) for s in s.split() if s.isdigit()] else None # total property value\n",
    "\n",
    "        if key_features:\n",
    "            possible_share = [feature for feature in key_features if 'share' in feature and ifisdigit(feature)]\n",
    "            if possible_share:\n",
    "                share_value = possible_share\n",
    "        if not share_value:\n",
    "            share_value_position = property_description.lower().find('% share') if property_description.lower().find('% share') else ''\n",
    "            share_value = property_description[share_value_position-2:share_value_position+20] if share_value_position else None\n",
    "\n",
    "    auction = True if 'auction' in property_description.lower() else 'N/A' # auction\n",
    "    ECP_link = soup.find(class_=\"_3z91CUtoOLTHRPqcxFHtvn\").get('href') if soup.find(class_=\"_3z91CUtoOLTHRPqcxFHtvn\") else None # EPC rating\n",
    "\n",
    "    temporary_property_data = pd.DataFrame(data={'property link': property_base_url, 'property address': property_address, 'property value': property_value,\n",
    "        'offer type': offer_type, 'property type': property_type, 'bedrooms': property_bedrooms, 'bathrooms': property_bathrooms,\n",
    "        'blueprint link': blueprint_url, 'agency name': agency_name, 'agency address': agency_address, 'agency link': agency_link,\n",
    "        'agency telephone': agency_telephone, 'contact form': agency_contact_form, 'features': [key_features], \n",
    "        'property description': property_description, 'cash': cash, 'shared': shared, 'share value': share_value,\n",
    "        'auction': auction, 'ECP link': ECP_link})\n",
    "    \n",
    "    property_data = pd.concat([property_data, temporary_property_data], ignore_index=True)\n",
    "\n",
    "# freehold/Leasehold\n",
    "# market info - last bought/sold\n",
    "# council tax - from council website based on address\n",
    "# check number of bedrooms in land registry\n",
    "# check land registry for information\n",
    "    \n",
    "# soup.find(class_\n",
    "# soup.find(class_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ece2b5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_data.to_excel(\"sales.xlsx\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f20f3d",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c16b3a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2189fb11",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723f7a2",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415a8b4",
   "metadata": {},
   "source": [
    "# Find properties/area/street demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51654f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.streetcheck.co.uk/postcode/ng32bp\n",
    "https://niceareas.co.uk/crime-map/for/nottingham/city/ng/ng1/ng1-5/crime-types/all/time-period/last-30-days/52.956200/-1.151200/\n",
    "https://www.police.uk/pu/your-area/nottinghamshire-police/st-anns/?tab=CrimeMap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f6425",
   "metadata": {},
   "source": [
    "## For buy property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75ced1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mortgage\n",
    "\n",
    "# https://www.moneysavingexpert.com/mortgages/best-buys/?journeyType=first-time-buyer&propertyValue=115000&depositAmount=20000&term=30&introTerms=Fixed&repaymentMethod=Repayment&sortBy=MonthlyRepaymentAmount&pageNumber=1&addFeeToBalance=true&productNoFee=false&noEarlyRepaymentCharge=false\n",
    "\n",
    "max_loan_age = 70\n",
    "\n",
    "Total_annual_income_1 = 25000 # including salary and additional side income\n",
    "Total_annual_income_2 = 0\n",
    "\n",
    "Deposit = 20000\n",
    "Budget_for_fees = 0\n",
    "Budget_for_repairs = 0\n",
    "\n",
    "Age_1 = 24\n",
    "Age_2 = 53\n",
    "\n",
    "Max_loan_duration = max_loan_age - max(Age_1, Age_2)\n",
    "\n",
    "# TODO scrape website for correct range based on above details\n",
    "Loan = (Total_annual_income_1+Total_annual_income_2)*4.5\n",
    "\n",
    "Interest_rate = 2.5/100\n",
    "\n",
    "Monthly_payment = Loan*Interest_rate\n",
    "\n",
    "Maximum_house_price_availability = Loan+Deposit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8386aea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132500.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Maximum_house_price_availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfacdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the annual yield of a rented property\n",
    "\n",
    "Annual_rental_income = 8400\n",
    "Prorperty_Purchase_price= 150.000\n",
    "Property_current_price = []\n",
    "\n",
    "annual_yield = 100*Annual_rental_income/Purchase_price\n",
    "\n",
    "if annual_yield < 7:\n",
    "    print(f'Current annual yield of {annual_yield} is below the ideal return!')\n",
    "else:\n",
    "    print(f'The current annual yield of {annual_yield} is performining extremely well!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "a7e067e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/toby-p/rightmove_webscraper.py/blob/cdb79a237d3e21ee7376dc88ad717af9b39b27e3/rightmove_webscraper/scraper.py#L151\n",
    "\n",
    "import bs4\n",
    "import requests\n",
    "\n",
    "status_code, content = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
